{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14009f50",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [6]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189d775b-60fe-4a43-bd06-3e159fd3f0d8",
   "metadata": {
    "papermill": {
     "duration": 0.041204,
     "end_time": "2022-12-16T11:45:08.493962",
     "exception": false,
     "start_time": "2022-12-16T11:45:08.452758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ETL with Spark on EMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22df453c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T11:45:08.512623Z",
     "iopub.status.busy": "2022-12-16T11:45:08.512298Z",
     "iopub.status.idle": "2022-12-16T11:45:08.631419Z",
     "shell.execute_reply": "2022-12-16T11:45:08.630758Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.129686,
     "end_time": "2022-12-16T11:45:08.633163",
     "exception": false,
     "start_time": "2022-12-16T11:45:08.503477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201fe093",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T11:45:08.644883Z",
     "iopub.status.busy": "2022-12-16T11:45:08.644637Z",
     "iopub.status.idle": "2022-12-16T11:45:08.647664Z",
     "shell.execute_reply": "2022-12-16T11:45:08.647092Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.010057,
     "end_time": "2022-12-16T11:45:08.648771",
     "exception": false,
     "start_time": "2022-12-16T11:45:08.638714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cat ~/.aws/credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a44c9e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T11:45:08.661865Z",
     "iopub.status.busy": "2022-12-16T11:45:08.661401Z",
     "iopub.status.idle": "2022-12-16T11:45:08.664579Z",
     "shell.execute_reply": "2022-12-16T11:45:08.664075Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.011572,
     "end_time": "2022-12-16T11:45:08.665664",
     "exception": false,
     "start_time": "2022-12-16T11:45:08.654092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aws_access_key_id = 'ASIAXZM22O2VXMSJVTXI'\n",
    "aws_secret_access_key = '62IWzY1AsVZnITCNp9hikk2ELwYfNS7xVK1V+dhI'\n",
    "aws_session_token = 'FwoGZXIvYXdzEJD//////////wEaDE77cQ7/zzF/oVWy1SLMASlsb2pkGODQhLhTFVx8mfl8SW1f4VJ/SMY5FYpQ5MbNBSo4LGpnh9wLCQAHBuS12qzab5KTCwDJ/8VlqhEiVzlGywupqKFy2hHAjt7UJoKpNEQ2z3riNgk+B6rGGHP/GVAuD2YGDAt7qtI6YkingE43ZEN1AooA5p/anIEqKJFzY/lp3Kfu1PAwp+EkOrRJFtjf3yrfI6ecrIDKf7tZ7+kMlnyzHyl4DjzKOZFtIgZLxtP1FmF1lK/iNmQS6W3VN2xtRVF18k12ED5kuijX7dycBjItO6kttJoQSsw99k7ARS03z3RtePpyX0RRHB2fhavQquhElDNfJUf27M2LlZyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a70261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T11:45:08.678783Z",
     "iopub.status.busy": "2022-12-16T11:45:08.678242Z",
     "iopub.status.idle": "2022-12-16T11:45:08.685077Z",
     "shell.execute_reply": "2022-12-16T11:45:08.684192Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015707,
     "end_time": "2022-12-16T11:45:08.687541",
     "exception": false,
     "start_time": "2022-12-16T11:45:08.671834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0xffff5748b7d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.2\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.access.key\", aws_access_key_id)\n",
    "conf.set(\"spark.hadoop.fs.s3a.secret.key\", aws_secret_access_key)\n",
    "conf.set(\"spark.hadoop.fs.s3a.session.token\", aws_session_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ddf25d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T11:45:08.701829Z",
     "iopub.status.busy": "2022-12-16T11:45:08.701356Z",
     "iopub.status.idle": "2022-12-16T11:45:08.705422Z",
     "shell.execute_reply": "2022-12-16T11:45:08.704063Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014678,
     "end_time": "2022-12-16T11:45:08.708054",
     "exception": false,
     "start_time": "2022-12-16T11:45:08.693376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = \"s3a://jaochin-dataset-fifa\"\n",
    "landing_zone = f\"{bucket}/landing/\"\n",
    "cleaned_zone = f\"{bucket}/cleaned/\"\n",
    "\n",
    "# cleaned_zone = f\"../Datalake/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca19020",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967f8dc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T11:45:08.723597Z",
     "iopub.status.busy": "2022-12-16T11:45:08.723109Z",
     "iopub.status.idle": "2022-12-16T11:45:08.900661Z",
     "shell.execute_reply": "2022-12-16T11:45:08.899762Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.18611,
     "end_time": "2022-12-16T11:45:08.902014",
     "exception": true,
     "start_time": "2022-12-16T11:45:08.715904",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/airflow/.local/lib/python3.7/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "/home/airflow/.local/lib/python3.7/site-packages/pyspark/bin/spark-class: line 71: /usr/lib/jvm/java-11-openjdk-amd64//bin/java: No such file or directory\n",
      "/home/airflow/.local/lib/python3.7/site-packages/pyspark/bin/spark-class: line 96: CMD: bad array subscript\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9784/1819407914.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[1;32m    193\u001b[0m             )\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             self._do_init(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f64bac-9a14-47b1-9e00-865b5a31176c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = spark.read.option(\"header\",\"true\").option(\"multiline\", \"true\").csv(landing_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a94871",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80aace",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView(\"staging_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347e0c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = spark.sql(\"\"\"\n",
    "    select\n",
    "        sofifa_id\n",
    "        , long_name\n",
    "        , age\n",
    "        , overall\n",
    "        , value_eur\n",
    "        , wage_eur\n",
    "        , team_position\n",
    "        , nationality\n",
    "        , club_name\n",
    "        , league_name\n",
    "    from\n",
    "        staging_data\n",
    "\"\"\")\n",
    "\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2687d9-cf8f-459d-9c4c-d78a23c0709f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_leagues = spark.sql(\"\"\"\n",
    "    select \n",
    "        row_number() over (order by league_name) as league_id\n",
    "        , league_name \n",
    "        , current_date() as date_oprt\n",
    "    from (\n",
    "        select distinct league_name from staging_data where league_name is not null order by league_name\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "table_leagues.createOrReplaceTempView(\"leagues\")\n",
    "table_leagues.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a892f9-c4d1-43c5-8436-dea69714dc8a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_clubs = spark.sql(\"\"\"\n",
    "    select \n",
    "        row_number() over (order by club.club_name) as club_id\n",
    "        , club.club_name \n",
    "        , league.league_id \n",
    "        , current_date() as date_oprt\n",
    "    from (\n",
    "        select distinct \n",
    "            club_name\n",
    "            , league_name \n",
    "        from staging_data \n",
    "        where club_name is not null \n",
    "        order by club_name\n",
    "    ) club\n",
    "    inner join leagues league \n",
    "        on league.league_name = club.league_name\n",
    "        and league.date_oprt = current_date()\n",
    "\"\"\")\n",
    "\n",
    "table_clubs.createOrReplaceTempView(\"clubs\")\n",
    "table_clubs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60a993-3a23-4beb-925c-6f2500aa93e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_positions = spark.sql(\"\"\"\n",
    "    select \n",
    "        row_number() over (order by team_position) as position_id\n",
    "        , team_position as position_name\n",
    "        , current_date() as date_oprt\n",
    "    from (\n",
    "        select distinct team_position from staging_data where team_position is not null order by team_position\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "table_positions.createOrReplaceTempView(\"positions\")\n",
    "table_positions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3310ea7-e205-4197-b777-d01de005e2d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_nationalities = spark.sql(\"\"\"\n",
    "    select \n",
    "        row_number() over (order by nationality) as nationality_id\n",
    "        , nationality as nationality_name \n",
    "        , current_date() as date_oprt\n",
    "    from (\n",
    "        select distinct nationality from staging_data where nationality is not null order by nationality\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "table_nationalities.createOrReplaceTempView(\"nationalities\")\n",
    "table_nationalities.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a6ef9e-19a7-4ff0-aebd-dadb629735dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_players = spark.sql(\"\"\"\n",
    "    select \n",
    "        sofifa_id as player_id\n",
    "        , replace(long_name, '\"', '') as player_name\n",
    "        , age as player_age\n",
    "        , overall as player_overall\n",
    "        , value_eur as player_value\n",
    "        , wage_eur as player_wage\n",
    "        , position.position_id\n",
    "        , nationality.nationality_id\n",
    "        , club.club_id\n",
    "        , current_date() as date_oprt\n",
    "    from (\n",
    "        select distinct \n",
    "            sofifa_id\n",
    "            , long_name\n",
    "            , age\n",
    "            , overall\n",
    "            , value_eur\n",
    "            , wage_eur\n",
    "            , team_position\n",
    "            , nationality\n",
    "            , club_name\n",
    "        from staging_data \n",
    "        order by sofifa_id\n",
    "    ) player\n",
    "    inner join positions position \n",
    "        on position.position_name = player.team_position\n",
    "        and position.date_oprt = current_date()\n",
    "    inner join nationalities nationality \n",
    "        on nationality.nationality_name = player.nationality\n",
    "        and nationality.date_oprt = current_date()\n",
    "    inner join clubs club \n",
    "        on club.club_name = player.club_name\n",
    "        and club.date_oprt = current_date()\n",
    "\"\"\")\n",
    "\n",
    "table_players.createOrReplaceTempView(\"players\")\n",
    "table_players.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f9b0a-0046-4f07-a4a1-ba245acca1d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_leagues.write.partitionBy(\"date_oprt\").mode(\"append\").option(\"header\",True).csv(cleaned_zone+\"/leagues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32255ed-6a0e-4775-a955-0bf8e5c41668",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_clubs.write.partitionBy(\"date_oprt\").mode(\"append\").option(\"header\",True).csv(cleaned_zone+\"/clubs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627a9be-6844-497c-9ee8-022190ea6ed3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_positions.write.partitionBy(\"date_oprt\").mode(\"append\").option(\"header\",True).csv(cleaned_zone+\"/positions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d3b517-d71e-43f6-a8a3-4ca2ab82bb4d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_nationalities.write.partitionBy(\"date_oprt\").mode(\"append\").option(\"header\",True).csv(cleaned_zone+\"/nationalities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0ee16-ac70-4d20-beac-da47d1251fa8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_players.write.partitionBy(\"date_oprt\").mode(\"append\").option(\"header\",True).csv(cleaned_zone+\"/players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0021c8-c8e9-4357-a556-e3e5333c2953",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  },
  "papermill": {
   "duration": 3.447689,
   "end_time": "2022-12-16T11:45:09.132160",
   "environment_variables": {},
   "exception": true,
   "input_path": "/opt/airflow/dags/datalake_etl_s3.ipynb",
   "output_path": "/opt/airflow/dags/datalake_etl_s3_output.ipynb",
   "parameters": {},
   "start_time": "2022-12-16T11:45:05.684471",
   "version": "2.1.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}